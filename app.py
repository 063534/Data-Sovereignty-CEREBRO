import streamlit as st
import os
import tempfile

# Kendi yazdÄ±ÄŸÄ±mÄ±z backend motorunu projemize dahil ediyoruz
from cerebro_brain import ask_cerebro 
# YENÄ°: PDF iÅŸleme motorumuzu (GÃ¶z ve HafÄ±za) dahil ediyoruz
from document_processor import process_and_save_pdf

# --- 1. SAYFA AYARLARI ---
st.set_page_config(page_title="Project CEREBRO", page_icon="ğŸ§ ", layout="wide")

# --- 2. YAN MENÃœ (SOL PANEL - SADE VE ÅIK) ---
with st.sidebar:
    if os.path.exists("neon_logo.png"):
        st.image("neon_logo.png", width=140)
    else:
        st.image("https://cdn-icons-png.flaticon.com/512/6356/6356649.png", width=120)
    
    st.title("Project CEREBRO")
    st.caption("Architect: BetÃ¼l SÄ±la KÃ¶roÄŸlu") # <-- Ä°MZAN KORUNDU
    st.markdown("---")
    
    st.write("**Hawkins Lab Status:**")
    st.success("ğŸŸ¢ System: ONLINE")
    st.error("ğŸš« Internet: OFFLINE") 
    st.info("ğŸ”’ Gate: CLOSED (Air-Gapped)")
    st.warning("ğŸ§  Engine: M2 Neural Core") # <-- M2 VURGUSU KORUNDU
    
    st.markdown("---")
    
    st.markdown("""<div style="text-align: center;"><br><i>"Hayatta en hakiki mÃ¼rÅŸit ilimdir."</i><br><br></div>""", unsafe_allow_html=True)
    if os.path.exists("imza.png"):
        st.image("imza.png", use_container_width=True)
    else:
        st.markdown("<h3 style='text-align: center; font-family: Brush Script MT, cursive;'>K. AtatÃ¼rk</h3>", unsafe_allow_html=True)
    st.markdown("""<div style="text-align: center;"><small>Cumhuriyet'in Ä°zinde, Bilimin IÅŸÄ±ÄŸÄ±nda.</small></div>""", unsafe_allow_html=True)

# --- 3. ANA EKRAN ---
st.title("ğŸ§  Project CEREBRO: Enterprise AI Node")
st.markdown("""
### *"Friends Don't Lie. Data Doesn't Leak to the Upside Down."*
*(ArkadaÅŸlar yalan sÃ¶ylemez. Veri, Ters DÃ¼nya'ya [Buluta] sÄ±zmaz.)*

Bu sistem, **Mimar BetÃ¼l SÄ±la KÃ¶roÄŸlu** tarafÄ±ndan geliÅŸtirilen; kurumsal ve endÃ¼striyel veri gÃ¼venliÄŸi iÃ§in **"Veri EgemenliÄŸi" (Data Sovereignty)** ilkesine dayalÄ± Ã§alÄ±ÅŸan yerel yapay zeka mimarisidir.
""") # <-- VÄ°ZYONUN KORUNDU

st.markdown("---") 

# --- 4. DÄ°L SEÃ‡Ä°MÄ° VE PDF YÃœKLEME (ANA EKRAN) ---
# EkranÄ± iki eÅŸit sÃ¼tuna bÃ¶ldÃ¼k ki dil seÃ§imi ve PDF kutusu yan yana Ã§ok ÅŸÄ±k dursun
col1, col2 = st.columns([1, 1]) 

with col1:
    selected_language = st.selectbox(
        "ğŸ› ï¸ Analiz Edilecek YazÄ±lÄ±m Dilini SeÃ§in:",
        ["Otomatik AlgÄ±la (Auto)", "C#", "Java", "Python", "JavaScript", "React", "HTML / CSS / Bootstrap", "SQL", "C / C++", "Swift", "DiÄŸer"]
    )

with col2:
    # YENÄ° EKLENEN PDF YÃœKLEME KUTUSU
    uploaded_file = st.file_uploader("ğŸ“‚ Kurumsal PDF / Log DosyasÄ± YÃ¼kle (RAG HafÄ±zasÄ±)", type=["pdf"])
    
    # EÄŸer kullanÄ±cÄ± bir PDF yÃ¼klerse...
    if uploaded_file is not None:
        with st.spinner("PDF Yerel HafÄ±zaya (ChromaDB) Ä°ÅŸleniyor..."):
            # DosyayÄ± geÃ§ici olarak M2 Mac'ine kaydet
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # AdÄ±m 2'de yazdÄ±ÄŸÄ±mÄ±z motoru Ã§alÄ±ÅŸtÄ±rÄ±p PDF'i hafÄ±zaya kazÄ±!
            chunk_count = process_and_save_pdf(tmp_file_path)
            st.success(f"âœ… DSGVO Uyumlu: Dosya dÄ±ÅŸarÄ± sÄ±zmadan {chunk_count} parÃ§a halinde yerel hafÄ±zaya ÅŸifrelendi!")

st.markdown("---")

# --- 5. SOHBET GEÃ‡MÄ°ÅÄ° ---
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Cerebro aktif. Verileriniz Upside Down'dan (Buluttan) korunuyor. Bilimin Ä±ÅŸÄ±ÄŸÄ±nda analize hazÄ±rÄ±m."}]

for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.chat_message("user", avatar="ğŸ§¢").write(msg["content"]) 
    else:
        st.chat_message("assistant", avatar="ğŸ§ ").write(msg["content"]) 

# --- 6. SORU-CEVAP KISMI ---
if prompt := st.chat_input("HatalÄ± kodu veya PDF ile ilgili sorunuzu buraya girin..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user", avatar="ğŸ§¢").write(prompt)

    with st.chat_message("assistant", avatar="ğŸ§ "):
        with st.spinner(f"Analyzing in Secure Mode ({selected_language})..."):
            try:
                full_response = ask_cerebro(prompt, selected_language)
                st.write(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error("âš ï¸ Mind Flayer SaldÄ±rÄ±sÄ±! (Model BaÄŸlantÄ± HatasÄ±)")
                st.info("LÃ¼tfen terminalden 'ollama run llama3' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.")
